# ResearchOnImageCaptioning
College Research Work

1. The dataset being used is Flickr8k dataset
2.  It consists of 6k training images
3.  1k validation images
4.  1k testing images
5.  Every image has 5 corresponding captions to it.
6.  The model used is VGG-16 pretrained model - <u>Visual Geometry Group</u>
7. 16 represents the # of weight layers in the model.
8.  It is a CNN based model containing 3X3 convolutional layers stacked on top of each other in increasing depth.
9.  More advanced model will be Resnet which can be trained upto 200 layers deep.
